{"componentChunkName":"component---src-templates-blog-post-js","path":"/1-billion-row/","result":{"data":{"markdownRemark":{"html":"<p>Recently, I've been working on an algorithmic trading project that involves processing tick data from thousands of stock market instruments in real-time from multiple sources. The task involves running algorithms on each tick and storing the data in a database for further analysis. I soon realized that Python was not well-suited for this task due to its Global Interpreter Lock (GIL) and single-threaded nature. However, since most of the codebase was written in Python, and completing the task took priority over optimizing the language, I decided to stick with Python. I soon realized I'll have to use one of the concurrency frameworks that Python offers to utilize the compute efficiently and offload any heavy lifting to the background (like DB read/writes)</p>\n<p>I also wondered what would happen if we use a naive approach to solve the <a href=\"https://1brc.dev/\"><code>1 Billion Row Challenge</code></a> whilst using the difference concurrency frameworks and here we are.</p>\n<p>Python offers multiple approaches to handle concurrent operations, each with its own strengths and trade-offs. Let's check out the three main concurrency frameworks: Threading, Multiprocessing, and AsyncIO, by implementing a simple yet challenging task: processing a large dataset of temperature measurements.</p>\n<h3>The Challenge</h3>\n<p>The <code>1 Billion Row Challenge</code> is a famous problem where the goal is to process a large dataset of temperature measurements and calculate the minimum, maximum, and mean temperature for each location. Ideally, this should be done in the shortest time possible, but we are more interested in the differences in performance between the various concurrency frameworks.</p>\n<p>We'll work with a dataset from the <a href=\"https://github.com/gunnarmorling/1brc/blob/main/data/weather_stations.csv\">1brc</a> repo on Github containing temperature measurements, where each line follows this format:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&lt;string:station>;&lt;double:temperature></code></pre></div>\n<p>Our task is to calculate the min, max, and mean temperature for each location. Simple enough? Let's see how different concurrency approaches handle this.</p>\n<p>The system I used for this blog was a MacBook Air M2 with 16 GB RAM and Apple's M2 chip (8-core CPU).</p>\n<h3>Threading: The I/O Specialist (concurrent.futures.ThreadPoolExecutor)</h3>\n<p>Python's threading is often misunderstood as a concept. Due to the Global Interpreter Lock (GIL), threads can't execute Python code truly in parallel. However, they're excellent for I/O-bound operations which is exactly the case here.</p>\n<p>We'll be using the <code>ThreadPoolExecutor</code> from the <code>concurrent.futures</code> module to run the threads instead of the <code>threading</code> module for simplicity and because of some features that <code>Executor</code> provides right out of the gate, which we don't get with the lower-level <code>threading</code> module.</p>\n<p>We'll be <code>mmap</code>-ing the file onto memory so that the read operations are efficient and then chunk-ify the file for each thread to process its chunk.</p>\n<p>The number of threads in the system is 8, one for each core, and hence there will be 8 chunks.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">calculate_boundaries</span><span class=\"token punctuation\">(</span>mm<span class=\"token punctuation\">,</span> num_chunks<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    file_size <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>mm<span class=\"token punctuation\">)</span>\n    approximate_chunk_size <span class=\"token operator\">=</span> file_size <span class=\"token operator\">//</span> num_chunks\n    boundaries <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    current_pos <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_chunks<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        chunk_start <span class=\"token operator\">=</span> current_pos\n        <span class=\"token keyword\">if</span> i <span class=\"token operator\">==</span> num_chunks <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            boundaries<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>chunk_start<span class=\"token punctuation\">,</span> file_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">break</span>\n        next_pos <span class=\"token operator\">=</span> <span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>chunk_start <span class=\"token operator\">+</span> approximate_chunk_size<span class=\"token punctuation\">,</span> file_size<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">while</span> next_pos <span class=\"token operator\">&lt;</span> file_size <span class=\"token keyword\">and</span> mm<span class=\"token punctuation\">[</span>next_pos<span class=\"token punctuation\">:</span>next_pos<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">!=</span> <span class=\"token string\">b'\\n'</span><span class=\"token punctuation\">:</span>\n            next_pos <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n        next_pos <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n        boundaries<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>chunk_start<span class=\"token punctuation\">,</span> next_pos<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        current_pos <span class=\"token operator\">=</span> next_pos\n    <span class=\"token keyword\">return</span> boundaries</code></pre></div>\n<p>Once we have the chunk boundaries, we are going to calculate the min, max, and mean temperature for each location.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">process_chunk</span><span class=\"token punctuation\">(</span>mm<span class=\"token punctuation\">,</span> start<span class=\"token punctuation\">,</span> end<span class=\"token punctuation\">,</span> chunk_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Starting chunk </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>chunk_id<span class=\"token punctuation\">}</span></span><span class=\"token string\">, processing </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token punctuation\">(</span>end<span class=\"token operator\">-</span>start<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token punctuation\">(</span><span class=\"token number\">1024</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> KB\"</span></span><span class=\"token punctuation\">)</span>\n    start_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    results <span class=\"token operator\">=</span> defaultdict<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'min'</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token string\">'inf'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'max'</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token string\">'-inf'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'sum'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'count'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n    chunk <span class=\"token operator\">=</span> mm<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">:</span>end<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> line <span class=\"token keyword\">in</span> chunk<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> line <span class=\"token keyword\">or</span> line<span class=\"token punctuation\">.</span>startswith<span class=\"token punctuation\">(</span><span class=\"token string\">'#'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">continue</span>\n        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n            station<span class=\"token punctuation\">,</span> temp <span class=\"token operator\">=</span> line<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">';'</span><span class=\"token punctuation\">)</span>\n            temp <span class=\"token operator\">=</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>temp<span class=\"token punctuation\">)</span>\n            results<span class=\"token punctuation\">[</span>station<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'min'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>results<span class=\"token punctuation\">[</span>station<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'min'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> temp<span class=\"token punctuation\">)</span>\n            results<span class=\"token punctuation\">[</span>station<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'max'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>results<span class=\"token punctuation\">[</span>station<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'max'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> temp<span class=\"token punctuation\">)</span>\n            results<span class=\"token punctuation\">[</span>station<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'sum'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> temp\n            results<span class=\"token punctuation\">[</span>station<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'count'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n        <span class=\"token keyword\">except</span> <span class=\"token punctuation\">(</span>ValueError<span class=\"token punctuation\">,</span> IndexError<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Warning: Skipping malformed line in chunk </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>chunk_id<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">continue</span>\n    processing_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start_time\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Finished chunk </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>chunk_id<span class=\"token punctuation\">}</span></span><span class=\"token string\"> in </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>processing_time<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.4f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> seconds\"</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span>results<span class=\"token punctuation\">)</span></code></pre></div>\n<p>Once all the <code>futures</code> are done processing, we can merge the results from all the chunks.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">merge_results</span><span class=\"token punctuation\">(</span>chunk_results<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    final_results <span class=\"token operator\">=</span> defaultdict<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'min'</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token string\">'inf'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'max'</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token string\">'-inf'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'sum'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'count'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> chunk_result <span class=\"token keyword\">in</span> chunk_results<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> station<span class=\"token punctuation\">,</span> stats <span class=\"token keyword\">in</span> chunk_result<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            final_results<span class=\"token punctuation\">[</span>station<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'min'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span>final_results<span class=\"token punctuation\">[</span>station<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'min'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> stats<span class=\"token punctuation\">[</span><span class=\"token string\">'min'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            final_results<span class=\"token punctuation\">[</span>station<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'max'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>final_results<span class=\"token punctuation\">[</span>station<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'max'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> stats<span class=\"token punctuation\">[</span><span class=\"token string\">'max'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            final_results<span class=\"token punctuation\">[</span>station<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'sum'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> stats<span class=\"token punctuation\">[</span><span class=\"token string\">'sum'</span><span class=\"token punctuation\">]</span>\n            final_results<span class=\"token punctuation\">[</span>station<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'count'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> stats<span class=\"token punctuation\">[</span><span class=\"token string\">'count'</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">return</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span>final_results<span class=\"token punctuation\">)</span></code></pre></div>\n<p>We then use <code>ThreadPoolExecutor</code> to run the threads.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">process_file</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> num_threads<span class=\"token operator\">=</span>os<span class=\"token punctuation\">.</span>cpu_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"\\n[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Starting processing with </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>num_threads<span class=\"token punctuation\">}</span></span><span class=\"token string\"> threads\"</span></span><span class=\"token punctuation\">)</span>\n    start_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    mm <span class=\"token operator\">=</span> open_mmap<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span>\n    boundaries <span class=\"token operator\">=</span> calculate_boundaries<span class=\"token punctuation\">(</span>mm<span class=\"token punctuation\">,</span> num_threads<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">with</span> ThreadPoolExecutor<span class=\"token punctuation\">(</span>max_workers<span class=\"token operator\">=</span>num_threads<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> executor<span class=\"token punctuation\">:</span>\n        futures <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>executor<span class=\"token punctuation\">.</span>submit<span class=\"token punctuation\">(</span>process_chunk<span class=\"token punctuation\">,</span> mm<span class=\"token punctuation\">,</span> start<span class=\"token punctuation\">,</span> end<span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span>\n                  <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>start<span class=\"token punctuation\">,</span> end<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>boundaries<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Processing chunks...\"</span></span><span class=\"token punctuation\">)</span>\n        chunk_results <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>future<span class=\"token punctuation\">.</span>result<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> future <span class=\"token keyword\">in</span> futures<span class=\"token punctuation\">]</span>\n    final_results <span class=\"token operator\">=</span> merge_results<span class=\"token punctuation\">(</span>chunk_results<span class=\"token punctuation\">)</span>\n    mm<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    total_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start_time\n    process <span class=\"token operator\">=</span> psutil<span class=\"token punctuation\">.</span>Process<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    memory_info <span class=\"token operator\">=</span> process<span class=\"token punctuation\">.</span>memory_info<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Total processing time: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>total_time<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.4f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> seconds\"</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Memory usage: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>memory_info<span class=\"token punctuation\">.</span>rss <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1024</span> <span class=\"token operator\">*</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> MB\"</span></span><span class=\"token punctuation\">)</span>\n    file_size <span class=\"token operator\">=</span> get_file_size<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span>\n    processing_speed <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>file_size <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1024</span> <span class=\"token operator\">*</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> total_time  <span class=\"token comment\"># MB/second</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Processing speed: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>processing_speed<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> MB/second\"</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> final_results</code></pre></div>\n<p>Once everything is assembled, we get the following result:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[2024-11-26 01:46:19.813633] Starting weather station data processing...\n\n[2024-11-26 01:46:19.813655] Starting processing with 8 threads\n[2024-11-26 01:46:19.818932] Starting chunk 0, processing 100.64 KB\n[2024-11-26 01:46:19.823863] Finished chunk 0 in 0.0049 seconds\n[2024-11-26 01:46:19.823899] Starting chunk 1, processing 100.64 KB\n[2024-11-26 01:46:19.824042] Starting chunk 2, processing 100.63 KB\n[2024-11-26 01:46:19.824061] Starting chunk 3, processing 100.63 KB\n[2024-11-26 01:46:19.834151] Finished chunk 2 in 0.0051 seconds\n[2024-11-26 01:46:19.828790] Finished chunk 1 in 0.0047 seconds\n[2024-11-26 01:46:19.838665] Finished chunk 3 in 0.0044 seconds\n[2024-11-26 01:46:19.834199] Starting chunk 4, processing 100.64 KB\n[2024-11-26 01:46:19.838944] Processing chunks...\n[2024-11-26 01:46:19.839058] Starting chunk 7, processing 100.57 KB\n[2024-11-26 01:46:19.834296] Starting chunk 5, processing 100.64 KB\n[2024-11-26 01:46:19.843717] Finished chunk 4 in 0.0046 seconds\n[2024-11-26 01:46:19.838746] Starting chunk 6, processing 100.63 KB\n[2024-11-26 01:46:19.848424] Finished chunk 7 in 0.0046 seconds\n[2024-11-26 01:46:19.852507] Finished chunk 5 in 0.0041 seconds\n[2024-11-26 01:46:19.856724] Finished chunk 6 in 0.0041 seconds\n[2024-11-26 01:46:19.886240] Total processing time: 0.0725 seconds\n[2024-11-26 01:46:19.886260] Memory usage: 43.39 MB\n[2024-11-26 01:46:19.886283] Processing speed: 10.85 MB/second</code></pre></div>\n<h3>Multiprocessing: The Compute Specialist (concurrent.futures.ProcessPoolExecutor)</h3>\n<p>Multiprocessing bypasses the GIL by spawning multiple Python processes and using all the CPU cores to execute the spawned processes(based on how you've configured it). It's ideal for CPU-bound tasks but comes with overhead from inter-process communication. As this problem does not require much compute power, there won't be much benefit in using multiprocessing over threading in this case.</p>\n<p>We'll be using the <code>ProcessPoolExecutor</code> from the <code>concurrent.futures</code> module to run the processes versus the <code>multiprocessing</code> module for simplicity and because of some right out the gate features with <code>Executor</code> that we don't get with lower level <code>multiprocessing</code> module.</p>\n<p>The code is almost the same as the one we used in the threading section, but instead of <code>ThreadPoolExecutor</code>, we'll be using <code>ProcessPoolExecutor</code> and we'll be using <code>cpu_count()</code> to get the number of CPU cores available on the system.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">process_file</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> num_processes<span class=\"token operator\">=</span>os<span class=\"token punctuation\">.</span>cpu_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"\\n[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Starting processing with </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>num_processes<span class=\"token punctuation\">}</span></span><span class=\"token string\"> processes\"</span></span><span class=\"token punctuation\">)</span>\n    start_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    boundaries <span class=\"token operator\">=</span> calculate_boundaries<span class=\"token punctuation\">(</span>open_mmap<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> num_processes<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Open mmap only for boundaries</span>\n\n    <span class=\"token keyword\">with</span> ProcessPoolExecutor<span class=\"token punctuation\">(</span>max_workers<span class=\"token operator\">=</span>num_processes<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> executor<span class=\"token punctuation\">:</span>\n        futures <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>executor<span class=\"token punctuation\">.</span>submit<span class=\"token punctuation\">(</span>process_chunk<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">,</span> start<span class=\"token punctuation\">,</span> end<span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span>\n                  <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>start<span class=\"token punctuation\">,</span> end<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>boundaries<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Processing chunks...\"</span></span><span class=\"token punctuation\">)</span>\n        chunk_results <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>future<span class=\"token punctuation\">.</span>result<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> future <span class=\"token keyword\">in</span> futures<span class=\"token punctuation\">]</span>\n\n    final_results <span class=\"token operator\">=</span> merge_results<span class=\"token punctuation\">(</span>chunk_results<span class=\"token punctuation\">)</span>\n    total_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start_time\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Total processing time: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>total_time<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.4f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> seconds\"</span></span><span class=\"token punctuation\">)</span>\n    file_size <span class=\"token operator\">=</span> get_file_size<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span>\n    processing_speed <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>file_size <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1024</span> <span class=\"token operator\">*</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> total_time  <span class=\"token comment\"># MB/second</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Processing speed: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>processing_speed<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> MB/second\"</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> final_results</code></pre></div>\n<p>Using <code>multiprocessing</code>, we get the following result-</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[2024-11-26 01:45:53.377859] Starting weather station data processing...\n\n[2024-11-26 01:45:53.377880] Starting processing with 8 processes\n[2024-11-26 01:45:53.398071] Processing chunks...\n[2024-11-26 01:45:53.440935] Starting chunk 0, processing 100.64 KB\n[2024-11-26 01:45:53.451718] Starting chunk 1, processing 100.64 KB\n[2024-11-26 01:45:53.453374] Starting chunk 2, processing 100.63 KB\n[2024-11-26 01:45:53.455376] Finished chunk 0 in 0.0144 seconds\n[2024-11-26 01:45:53.458929] Starting chunk 3, processing 100.63 KB\n[2024-11-26 01:45:53.459244] Starting chunk 4, processing 100.64 KB\n[2024-11-26 01:45:53.464057] Starting chunk 5, processing 100.64 KB\n[2024-11-26 01:45:53.464292] Starting chunk 6, processing 100.63 KB\n[2024-11-26 01:45:53.467697] Finished chunk 2 in 0.0143 seconds\n[2024-11-26 01:45:53.467865] Finished chunk 3 in 0.0089 seconds\n[2024-11-26 01:45:53.469094] Finished chunk 5 in 0.0050 seconds\n[2024-11-26 01:45:53.469647] Finished chunk 1 in 0.0179 seconds\n[2024-11-26 01:45:53.470049] Finished chunk 6 in 0.0057 seconds\n[2024-11-26 01:45:53.470683] Starting chunk 7, processing 100.57 KB\n[2024-11-26 01:45:53.470916] Finished chunk 4 in 0.0117 seconds\n[2024-11-26 01:45:53.476174] Finished chunk 7 in 0.0055 seconds\n[2024-11-26 01:45:53.529482] Total processing time: 0.1515 seconds\n[2024-11-26 01:45:53.529519] Memory usage: 48.16 MB\n[2024-11-26 01:45:53.529546] Processing speed: 5.19 MB/second</code></pre></div>\n<p>The processing speed is approximately half of what we observed with multithreading. This can be attributed to the fact that most of the time in this problem is spent dividing and reading chunks of the file rather than performing heavy computations, as operations like min/max/mean are relatively lightweight. Multiprocessing adds overhead by pickling data and creating copies for each process, which contributes to the reduced efficiency compared to multithreading in this case.</p>\n<h3>AsyncIO: Multitasking with Coroutines</h3>\n<p>AsyncIO in Python is a powerful way to handle multiple tasks at once, but there's a catch! The tasks will still run on a single thread. Instead of juggling tasks like a traditional multithreading approach, AsyncIO is more like a coordinated system where you put tasks in and it handles when to switch to another task, especially when you're dealing with stuff like making network calls or reading/writing files.</p>\n<p>What makes AsyncIO particularly effective is how it handles task switching. Rather than randomly jumping between tasks, it lets them decide when it's a good time to pause(yield) and let another task take over. This is super efficient because you're not wasting resources constantly switching between tasks(the event loop handles that). If you're building something that needs to handle tons of simultaneous connections (like a chat app or a web scraper), AsyncIO might just be answer!</p>\n<p>In the code, the event loop begins by using <code>asyncio.run()</code> to start the main coroutine. Using a <code>tasks</code> list to store each task that will process their respective chunk and then gathering all of them up</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">async</span> <span class=\"token keyword\">def</span> <span class=\"token function\">process_file</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> num_chunks<span class=\"token operator\">=</span>os<span class=\"token punctuation\">.</span>cpu_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"\\n[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Starting processing with </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>num_chunks<span class=\"token punctuation\">}</span></span><span class=\"token string\"> chunks\"</span></span><span class=\"token punctuation\">)</span>\n    start_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    mm <span class=\"token operator\">=</span> <span class=\"token keyword\">await</span> open_mmap<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span>\n    boundaries <span class=\"token operator\">=</span> calculate_boundaries<span class=\"token punctuation\">(</span>mm<span class=\"token punctuation\">,</span> num_chunks<span class=\"token punctuation\">)</span>\n    tasks <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>process_chunk<span class=\"token punctuation\">(</span>mm<span class=\"token punctuation\">,</span> start<span class=\"token punctuation\">,</span> end<span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>start<span class=\"token punctuation\">,</span> end<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>boundaries<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n    chunk_results <span class=\"token operator\">=</span> <span class=\"token keyword\">await</span> asyncio<span class=\"token punctuation\">.</span>gather<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>tasks<span class=\"token punctuation\">)</span>\n    final_results <span class=\"token operator\">=</span> merge_results<span class=\"token punctuation\">(</span>chunk_results<span class=\"token punctuation\">)</span>\n    mm<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    total_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start_time\n    process <span class=\"token operator\">=</span> psutil<span class=\"token punctuation\">.</span>Process<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    memory_info <span class=\"token operator\">=</span> process<span class=\"token punctuation\">.</span>memory_info<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Total processing time: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>total_time<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.4f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> seconds\"</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Memory usage: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>memory_info<span class=\"token punctuation\">.</span>rss <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1024</span> <span class=\"token operator\">*</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> MB\"</span></span><span class=\"token punctuation\">)</span>\n    file_size <span class=\"token operator\">=</span> <span class=\"token keyword\">await</span> get_file_size<span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">)</span>\n    processing_speed <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>file_size <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1024</span> <span class=\"token operator\">*</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> total_time  <span class=\"token comment\"># MB/second</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"[</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">] Processing speed: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>processing_speed<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> MB/second\"</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Using AsyncIO, we get the following result:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[2024-11-26 01:44:49.565130] Starting weather station data processing...\n\n[2024-11-26 01:44:49.565309] Starting processing with 8 chunks\n[2024-11-26 01:44:49.568495] Starting chunk 0, processing 100.64 KB\n[2024-11-26 01:44:49.573645] Finished chunk 0 in 0.0051 seconds\n[2024-11-26 01:44:49.573817] Starting chunk 1, processing 100.64 KB\n[2024-11-26 01:44:49.578438] Finished chunk 1 in 0.0046 seconds\n[2024-11-26 01:44:49.578500] Starting chunk 2, processing 100.63 KB\n[2024-11-26 01:44:49.583211] Finished chunk 2 in 0.0047 seconds\n[2024-11-26 01:44:49.583296] Starting chunk 3, processing 100.63 KB\n[2024-11-26 01:44:49.587893] Finished chunk 3 in 0.0046 seconds\n[2024-11-26 01:44:49.587964] Starting chunk 4, processing 100.64 KB\n[2024-11-26 01:44:49.592638] Finished chunk 4 in 0.0047 seconds\n[2024-11-26 01:44:49.592709] Starting chunk 5, processing 100.64 KB\n[2024-11-26 01:44:49.597871] Finished chunk 5 in 0.0052 seconds\n[2024-11-26 01:44:49.597924] Starting chunk 6, processing 100.63 KB\n[2024-11-26 01:44:49.602060] Finished chunk 6 in 0.0041 seconds\n[2024-11-26 01:44:49.602100] Starting chunk 7, processing 100.57 KB\n[2024-11-26 01:44:49.606170] Finished chunk 7 in 0.0041 seconds\n[2024-11-26 01:44:49.636362] Total processing time: 0.0709 seconds\n[2024-11-26 01:44:49.636381] Memory usage: 47.70 MB\n[2024-11-26 01:44:49.636405] Processing speed: 11.08 MB/second</code></pre></div>\n<p>This method appears to be the fastest among the three, which makes sense because AsyncIO is designed to efficiently handle tasks involving significant I/O, as is the case in our scenario.</p>\n<h3>Performance Showdown</h3>\n<p>Running these implementations on my MacBook Air M2 with 16 GB RAM and Apple's M2 chip (8-core CPU):</p>\n<ol>\n<li>\n<p><strong>Threading</strong></p>\n<ul>\n<li>Processing Time: 0.0725s</li>\n<li>Processing Speed: 10.85 MB/second</li>\n<li>Memory Usage: 43.39 MB</li>\n</ul>\n</li>\n<li>\n<p><strong>Multiprocessing</strong></p>\n<ul>\n<li>Processing Time:  0.1515s</li>\n<li>Processing Speed: 10.85 MB/second</li>\n<li>Memory Usage: 48.16 MB</li>\n</ul>\n</li>\n<li>\n<p><strong>AsyncIO</strong></p>\n<ul>\n<li>Processing Time: 0.0709s</li>\n<li>Processing Speed: 11.08 MB/second</li>\n<li>Memory Usage: 47.70 MB</li>\n</ul>\n</li>\n</ol>\n<h3>When to Use Which?</h3>\n<ul>\n<li>\n<p><strong>Use Threading When:</strong></p>\n<ul>\n<li>Your task is I/O bound (file operations, network calls)</li>\n<li>You need to share memory between threads</li>\n<li>You want simple implementation over maximum efficiency</li>\n</ul>\n</li>\n<li>\n<p><strong>Use Multiprocessing When:</strong></p>\n<ul>\n<li>Your task is CPU bound (e.g., computationally intensive operations like data processing or image rendering)</li>\n<li>You have lots of RAM to spare</li>\n<li>You need true parallelism to utilize multiple cores</li>\n</ul>\n</li>\n<li>\n<p><strong>Use AsyncIO When:</strong></p>\n<ul>\n<li>You’re managing many concurrent I/O-bound tasks (e.g., web scraping, chat servers)</li>\n<li>Tasks involve frequent waiting or latency (e.g., network responses, database queries)</li>\n<li>You want a single-threaded, cooperative multitasking model to handle tasks efficiently</li>\n</ul>\n</li>\n</ul>\n<h3>The Verdict</h3>\n<p>After analyzing the performance metrics of the three concurrency approaches, it's clear that both multithreading and AsyncIO are suitable options for tackling the 1 Billion Row Challenge. Both methods leveraged the I/O-bound nature of the task to achieve significant performance boosts. AsyncIO, in particular, demonstrated the fastest processing time and highest processing speed, making it an attractive choice for tasks involving concurrent I/O operations. Multithreading, on the other hand, offered a simpler implementation and competitive performance, making it a viable alternative.</p>\n<p>Stay tuned for more performance-tuning adventures!</p>\n<hr>\n<p><em>The complete code and dataset are available in my <a href=\"https://github.com/arnavpisces/blogs/tree/main/1-billion-row\">GitHub repository</a>.</em></p>","frontmatter":{"title":"Uncovering the 1 Billion Row Challenge: A Naive Approach Comparison Between Various Concurrency Frameworks in Python","date":"November 14, 2024"}}},"pageContext":{"slug":"/1-billion-row/"}},"staticQueryHashes":[],"slicesMap":{}}